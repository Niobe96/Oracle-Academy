import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import xgboost as xgb
import shap
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import platform

if platform.system() == 'Windows':
    plt.rc('font', family='Malgun Gothic') 

# 1. ë°ì´í„° ì…ë ¥
raw_data = [
    ['TRAIN_0000', 2009, 'CT005', 'ì´ì»¤ë¨¸ìŠ¤', 'Series A', 4126.0, '', '', 56.0, 3365.0, 4764.0, 4.71, '', 0.3],
    ['TRAIN_0001', 2023, 'CT006', 'í•€í…Œí¬', 'Seed', 4167.0, 'checked', '', 80.0, 4069.0, 279.0, 1.00, '2500-3500', 0.8],
    ['TRAIN_0002', 2018, 'CT007', 'ê¸°ìˆ ', 'Series A', 3132.0, 'checked', 'checked', 54.0, 6453.0, 12141.0, 4.00, '3500-4500', 0.5],
    ['TRAIN_0003', 2016, 'CT006', '', 'Seed', 3245.0, 'checked', 'checked', '', 665.0, 10547.0, 2.97, '', 0.7],
    ['TRAIN_0004', 2020, 'CT002', 'ì—ë“€í…Œí¬', 'Seed', 1969.0, '', 'checked', 94.0, 829.0, 9810.0, 1.00, '1500-2500', 0.1],
    ['TRAIN_0005', 2012, 'CT008', 'ê¸°ìˆ ', 'Series C', 3801.0, '', 'checked', 69.0, 6505.0, 12722.0, 3.00, '2500-3500', 0.6],
    ['TRAIN_0006', 2008, 'CT010', '', 'Series B', 818.0, '', 'checked', '', 3049.0, 666.0, 0.76, '2500-3500', 0.4],
    ['TRAIN_0007', 2020, 'CT002', 'ê²Œì„', 'Series A', 2617.0, '', '', 80.0, 5579.0, 5399.0, 4.00, '3500-4500', 0.7],
    ['TRAIN_0008', 2005, 'CT002', '', 'Series B', '', '', '', 2722.0, 2568.0, 4.94, '', 0.9],
    ['TRAIN_0009', 2009, 'CT008', '', 'Series B', 1757.0, '', '', 285.0, 11758.0, 2.33, '', 0.5]
]

columns = ['ID', 'ì„¤ë¦½ì—°ë„', 'êµ­ê°€', 'ë¶„ì•¼', 'íˆ¬ìë‹¨ê³„', 'ì§ì›ìˆ˜', 'ì¸ìˆ˜ì—¬ë¶€1', 'ì¸ìˆ˜ì—¬ë¶€2',
           'ê³ ê°ìˆ˜', 'ì´íˆ¬ìê¸ˆ', 'ì—°ë§¤ì¶œ', 'í‰ì ', 'ê¸°ì—…ê°€ì¹˜', 'ì„±ê³µí™•ë¥ ']

df = pd.DataFrame(raw_data, columns=columns)

# 2. ê²°ì¸¡ ë³´ì • ë° ë¼ë²¨ë§ ì „ì²˜ë¦¬
df['ì„±ê³µí™•ë¥ '] = df['ì„±ê³µí™•ë¥ '].replace('', np.nan).astype(float)
df['ì„±ê³µí™•ë¥ '] = df['ì„±ê³µí™•ë¥ '].fillna(method='ffill')  # ê²°ì¸¡ê°’ ë³´ì •

df['ì„¤ë¦½ì—°ë„'] = 2025 - df['ì„¤ë¦½ì—°ë„']
df['êµ­ê°€'] = df['êµ­ê°€'].str.extract(r'(\d)$').astype(float)

df['ë¶„ì•¼'] = df['ë¶„ì•¼'].fillna('').replace('', 'ì—†ìŒ')
field_map = {name: idx for idx, name in enumerate(df['ë¶„ì•¼'].unique())}
df['ë¶„ì•¼'] = df['ë¶„ì•¼'].map(field_map)

stage_map = {'Seed': 1, 'Series A': 2, 'Series B': 3, 'Series C': 4}
df['íˆ¬ìë‹¨ê³„'] = df['íˆ¬ìë‹¨ê³„'].map(stage_map)

df['ì§ì›ìˆ˜'] = df['ì§ì›ìˆ˜'].replace('', 0).fillna(0).astype(float).astype(int)
df['ì¸ìˆ˜ì—¬ë¶€1'] = df['ì¸ìˆ˜ì—¬ë¶€1'].apply(lambda x: 1 if x == 'checked' else 0)
df['ì¸ìˆ˜ì—¬ë¶€2'] = df['ì¸ìˆ˜ì—¬ë¶€2'].apply(lambda x: 1 if x == 'checked' else 0)

df['ê³ ê°ìˆ˜'] = df['ê³ ê°ìˆ˜'].replace('', 0).fillna(0).astype(float) * 1_000_000
df['ì´íˆ¬ìê¸ˆ'] = df['ì´íˆ¬ìê¸ˆ'].replace('', 0).fillna(0).astype(float) * 100_000_000
df['ì—°ë§¤ì¶œ'] = df['ì—°ë§¤ì¶œ'].replace('', 0).fillna(0).astype(float) * 100_000_000

df['ê¸°ì—…ê°€ì¹˜'] = df['ê¸°ì—…ê°€ì¹˜'].astype(str).apply(
    lambda val: ((int(val.split('-')[0]) + int(val.split('-')[1])) / 2) * 1_000_000_000 if '-' in val else 0)

df['í‰ì '] = df['í‰ì '].replace('', 0).fillna(0).astype(float)

# 3. ì •ê·œí™”
numeric_cols = ['ì„¤ë¦½ì—°ë„', 'êµ­ê°€', 'ë¶„ì•¼', 'íˆ¬ìë‹¨ê³„', 'ì§ì›ìˆ˜',
                'ì¸ìˆ˜ì—¬ë¶€1', 'ì¸ìˆ˜ì—¬ë¶€2', 'ê³ ê°ìˆ˜', 'ì´íˆ¬ìê¸ˆ',
                'ì—°ë§¤ì¶œ', 'í‰ì ', 'ê¸°ì—…ê°€ì¹˜']

scaler = MinMaxScaler()
df[numeric_cols] = scaler.fit_transform(df[numeric_cols])

# 4. XGBoost ëª¨ë¸ í•™ìŠµ
X = df.drop(columns=['ID', 'ì„±ê³µí™•ë¥ '])
y = df['ì„±ê³µí™•ë¥ ']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = xgb.XGBRegressor(
    objective='reg:squarederror',
    n_estimators=20,
    max_depth=3,
    learning_rate=0.1,
    random_state=42,
    verbosity=0
)

model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# 5. ì„±ëŠ¥ í‰ê°€
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("ğŸ“Š MSE:", mse)
print("ğŸ“ˆ RÂ²:", r2)

# 6. SHAP í•´ì„
# SHAP Explainer ìƒì„±
explainer = shap.Explainer(model, X_train)

# SHAP ê°’ ê³„ì‚°
shap_values = explainer(X_train)

# ì „ì²´ ë³€ìˆ˜ ì˜í–¥ë ¥ ì‹œê°í™”
shap.summary_plot(shap_values, X_train)

# 'êµ­ê°€' ì œì™¸í•˜ê³  SHAP ì¬ê³„ì‚°
X_train_reduced = X_train.drop(columns=['êµ­ê°€'])
explainer_reduced = shap.Explainer(model, X_train_reduced)
shap_values_reduced = explainer_reduced(X_train_reduced)

# ìƒˆë¡œìš´ summary plot
shap.summary_plot(shap_values_reduced, X_train_reduced)
